{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisa informações gerais dos arquivos de Twitter #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arquivo que analisa o volume de tweets de cada série"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bibliotecas\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pathlib import Path\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from datetime import date\n",
    "\n",
    "#InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nomes_series = pd.read_csv('input_twitter_analysis.csv')\n",
    "nomes_series['data_estreia'] = pd.to_datetime(nomes_series['data_estreia'], format=\"%Y-%m-%d\", errors = 'coerce')\n",
    "print(nomes_series['data_estreia'].dtypes)\n",
    "nomes_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def droparDup(dataframe):\n",
    "    dataframe.drop_duplicates(subset=['id'], inplace=True)\n",
    "    \n",
    "def formatarData(dataframe):\n",
    "    dataframe['date'] = pd.to_datetime(dataframe['date'], format=\"%Y-%m-%d\", errors = 'coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for serie in nomes_series['nome']:\n",
    "    df_serie = pd.read_csv('series_dataset/'+serie+'.csv', error_bad_lines=False)\n",
    "    df_serie_pre = pd.read_csv('series_dataset/'+serie+'-pre.csv', error_bad_lines=False)\n",
    "    df_serie = pd.concat([df_serie, df_serie_pre])\n",
    "    droparDup(df_serie)\n",
    "    \n",
    "    print(f\"{serie}\")\n",
    "    df_serie.to_csv(f\"series_dataset_completo/{serie}_completo.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtrarDatas(dataframe, data_inicial, data_final):\n",
    "    filtro_dados = (dataframe[\"date\"] >  data_inicial) & (dataframe[\"date\"] < data_final)\n",
    "    #print(dataframe[filtro_dados])\n",
    "    return dataframe[filtro_dados].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countPre(dataframe, data_estreia):\n",
    "    data_final = data_estreia - pd.DateOffset(days=3)\n",
    "    data_inicial = data_estreia - pd.DateOffset(days=76)\n",
    "    #print(f\"Count Pre: Final: {data_final}, Inicial: {data_inicial}\")\n",
    "    \n",
    "    return filtrarDatas(dataframe, data_inicial, data_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countDurante(dataframe, data_estreia):\n",
    "    data_final = data_estreia + pd.DateOffset(days=4)\n",
    "    data_inicial = data_estreia - pd.DateOffset(days=4)\n",
    "    #print(f\"Count Durante: Final: {data_final}, Inicial: {data_inicial}\")\n",
    "    \n",
    "    return filtrarDatas(dataframe, data_inicial, data_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countPos(dataframe, data_estreia):\n",
    "    data_final = data_estreia + pd.DateOffset(days=151)\n",
    "    data_inicial = data_estreia + pd.DateOffset(days=3)\n",
    "    #print(f\"Count Pos: Final: {data_final}, Inicial: {data_inicial}\")\n",
    "    \n",
    "    return filtrarDatas(dataframe, data_inicial, data_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countTotal(dataframe, data_estreia):\n",
    "    data_final = data_estreia + pd.DateOffset(days=151)\n",
    "    data_inicial = data_estreia - pd.DateOffset(days=76)\n",
    "    #print(f\"Count Total: Final: {data_final}, Inicial: {data_inicial}\")\n",
    "    \n",
    "    return filtrarDatas(dataframe, data_inicial, data_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_df = []\n",
    "for index, linha in nomes_series.iterrows():\n",
    "    row = []\n",
    "    df_serie = pd.read_csv(f\"series_dataset_completo/{linha['nome']}_completo.csv\")\n",
    "    #df_serie[df_serie[\"id\"].duplicated()]\n",
    "    formatarData(df_serie)\n",
    "    \n",
    "    row.append(linha['nome'])\n",
    "    row.append(linha['data_estreia']) \n",
    "    row.append(countPre(df_serie, linha['data_estreia']))\n",
    "    row.append(countDurante(df_serie,linha['data_estreia']))\n",
    "    row.append(countPos(df_serie, linha['data_estreia']))\n",
    "    row.append(countTotal(df_serie, linha['data_estreia']))\n",
    "    #print(\"\\n\\n\\n\")\n",
    "    \n",
    "    lista_df.append(row)\n",
    "\n",
    "df = pd.DataFrame(lista_df, columns = ['Nome', 'DataEstreia', 'CountPre', 'CountDurante', 'CountPos', 'CountTotal'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f\"series_dataset_count/dataset_count.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_df[1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in lista_df:\n",
    "    setDataframe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todos_df.groupby([\"nome_serie\", \"date\"])[\"date\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantificar hashtags associadas ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hash = lista_df[1][lista_df[1][\"hashtags\"].notna()]\n",
    "# lista_df[1][lista_df[1][\"hashtags\"].isna()]\n",
    "# lista_df[1][\"hashtags\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hash[\"hashtags\"] = df_hash[\"hashtags\"].apply(lambda x: eval(str(x)))\n",
    "s = df_hash[\"hashtags\"].explode()\n",
    "counts = s.value_counts()\n",
    "counts.to_csv('hashtag.csv',index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizar série temporal ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtro_dados = (df_TheWitcher[\"date\"] > pd.Timestamp(2020, 1, 1)) & (df_TheWitcher[\"date\"] <  pd.Timestamp(2020, 2, 8)\n",
    "\n",
    "#Criar tuplas de visualização\n",
    "tuplas_vis = []\n",
    "for df in lista_df:\n",
    "\n",
    "    data_final = df['date'].iloc[0] - pd.DateOffset(days=210)\n",
    "    data_inicial = df['date'].iloc[-1]\n",
    "\n",
    "    filtro_dados = (df[\"date\"] >  data_inicial) & (df[\"date\"] < data_final)\n",
    "    y = df[filtro_dados]['date'].value_counts()\n",
    "    x = df[filtro_dados]['date'].value_counts().index.tolist()\n",
    "\n",
    "    tuplas_vis.append((x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10), sharey=False)\n",
    "\n",
    "sns.lineplot(ax=axes[0,0], x = tuplas_vis[0][0], y = tuplas_vis[0][1], color=\"salmon\")\n",
    "axes[0,0].tick_params(rotation=90, axis='x')\n",
    "axes[0,0].set_title(nomes_series[0])\n",
    "axes[0,0].set_ylabel('Número Total de Twitts')\n",
    "axes[0,0].set_xlabel('Dia')\n",
    "\n",
    "sns.lineplot(ax=axes[0,1], x = tuplas_vis[1][0], y = tuplas_vis[1][1], color=\"salmon\")\n",
    "axes[0,1].tick_params(rotation=90, axis='x')\n",
    "axes[0,1].set_title(nomes_series[1])\n",
    "axes[0,1].set_ylabel('Número Total de Twitts')\n",
    "axes[0,1].set_xlabel('Dia')\n",
    "\n",
    "sns.lineplot(ax=axes[1,0], x = tuplas_vis[2][0], y = tuplas_vis[2][1], color=\"salmon\")\n",
    "axes[1,0].tick_params(rotation=90, axis='x')\n",
    "axes[1,0].set_title(nomes_series[2])\n",
    "axes[1,0].set_ylabel('Número Total de Twitts')\n",
    "axes[1,0].set_xlabel('Dia')\n",
    "\n",
    "sns.lineplot(ax=axes[1,1], x = tuplas_vis[3][0], y = tuplas_vis[3][1], color=\"salmon\")\n",
    "axes[1,1].tick_params(rotation=90, axis='x')\n",
    "axes[1,1].set_title(nomes_series[3])\n",
    "axes[1,1].set_ylabel('Número Total de Twitts')\n",
    "axes[1,1].set_xlabel('Dia')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "981b974d7feb576734841ecc0870447e502dc04c560ef5e72ee5cc0ac2a5053d"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
